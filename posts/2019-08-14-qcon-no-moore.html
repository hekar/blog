<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png"/><link rel="manifest" href="/favicon/site.webmanifest"/><link rel="mask-icon" href="/favicon/safari-pinned-tab.svg" color="#000000"/><link rel="shortcut icon" href="/favicon/favicon.ico"/><meta name="msapplication-TileColor" content="#000000"/><meta name="msapplication-config" content="/favicon/browserconfig.xml"/><meta name="theme-color" content="#000"/><link rel="alternate" type="application/rss+xml" href="/feed.xml"/><meta name="description" content="Mov Blog - Mov instructions building complete systems."/><meta property="og:image" content="https://og-image.vercel.app/Next.js%20Blog%20Starter%20Example.png?theme=light&amp;md=1&amp;fontSize=100px&amp;images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fnextjs-black-logo.svg"/><title>QCon - No Moore Left to Give | Mov Blog</title><meta property="og:image" content=""/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.2.0/styles/github.min.css"/><meta name="next-head-count" content="17"/><link rel="preload" href="/blog/_next/static/css/2fb5138e8c8527d4.css" as="style"/><link rel="stylesheet" href="/blog/_next/static/css/2fb5138e8c8527d4.css" data-n-g=""/><link rel="preload" href="/blog/_next/static/css/cf121497002c184d.css" as="style"/><link rel="stylesheet" href="/blog/_next/static/css/cf121497002c184d.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/blog/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/blog/_next/static/chunks/webpack-4d5208940e01a3dc.js" defer=""></script><script src="/blog/_next/static/chunks/framework-4556c45dd113b893.js" defer=""></script><script src="/blog/_next/static/chunks/main-ee613568123ae71a.js" defer=""></script><script src="/blog/_next/static/chunks/pages/_app-6cff62718d504bfc.js" defer=""></script><script src="/blog/_next/static/chunks/34-3cca6a3b523c4f79.js" defer=""></script><script src="/blog/_next/static/chunks/pages/posts/%5Bslug%5D-c71d95ce7626635e.js" defer=""></script><script src="/blog/_next/static/8hHALvY9GgZh87Tdh2K_K/_buildManifest.js" defer=""></script><script src="/blog/_next/static/8hHALvY9GgZh87Tdh2K_K/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="min-h-screen"><div class="border-b bg-accent-1 border-accent-2"><div class="container mx-auto px-5"><div class="py-2 text-center text-sm"></div></div></div><main><div class="container mx-auto px-5"><section class="mb-16"><h2 class="text-2xl md:text-4xl font-bold tracking-tight md:tracking-tighter leading-tight mb-8 mt-8"><a class="hover:underline" href="/blog">Mov Log</a></h2><a class="hover:underline cursor-pointer"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2716%27%20height=%2716%27/%3e"/></span><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="align-middle pt-4" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img src="/blog/_next/static/media/back.e4267c42.png" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="align-middle pt-4" loading="lazy"/></noscript></span> <span class="md:text-xl">Articles</span></a></section><article class="mb-32"><div class="max-w-2xl"><h1 class="text-4xl md:text-4xl lg:text-4xl font-bold tracking-tighter leading-tight md:leading-none mb-4">QCon - No Moore Left to Give</h1><div class="block mb-6"><div class="flex items-center"><div class="text-xl font-bold">Hekar Khani</div></div></div><div class="mb-6 text-lg"><time dateTime="2019-08-14">August	14, 2019</time></div></div><div class="max-w-6xl"><div class="markdown-styles_markdown__h_8de"><p>Bryan Cantrill is one of my favorite presenters, so I was excited to see that he'd be giving a keynote at QCon. For a long time, computer enthuasaists have been talking about the end of Moore's law and what it means for computing. What Cantrill explains is that Moore's law is close to ending, it's not the end of the world, but developers aren't going to get the "free" performance increases we've seen in the past.</p>
<hr>
<blockquote>
<p><a href="https://www.infoq.com/presentations/moore-law-expiring/">No Moore Left to Give: Enterprise Computing after Moore's Law</a></p>
<p>This post is based on a <a href="https://www.infoq.com/qconnewyork2019/">keynote presentation</a> by Bryan Cantrill and is <a href="https://www.infoq.com/presentations/moore-law-expiring/?itm_source=infoq&#x26;itm_medium=popular_widget&#x26;itm_campaign=popular_content_list&#x26;itm_content=">freely available on the InfoQ website.</a></p>
</blockquote>
<p>Bryan references three "laws" in his talk.</p>
<p>The laws referenced are Dennard Scaling, Moore's Law and Amdahl's Law.</p>
<p>What Bryan argues is that Moore's Law is nearing its end and transistor sizes below 7nm are going to be more expensive and yield less benefits going forward. Programmers have become accustomed to computers becoming faster and cheaper every year, but this may no longer be the case.</p>
<p>I will quickly go over the three laws referenced by Cantrill in his talk.</p>
<h3>Dennard Scaling</h3>
<p>From Wikipedia: <a href="https://en.wikipedia.org/wiki/Dennard_scaling">wiki/Dennard_scaling</a></p>
<blockquote>
<p>Dennard scaling, also known as MOSFET scaling, is a scaling law based on a 1974 paper co-authored by Robert H. Dennard, after whom it is named. Originally formulated for MOSFETs, it states, roughly, that as transistors get smaller, their power density stays constant, so that the power use stays in proportion with area; both voltage and current scale (downward) with length.</p>
</blockquote>
<p>Dennard scaling meant that processors could go faster simply by increasing the frequency. From 100Mhz to 2GHz to 3GHz and so on. Frequency increases broke down somewhere in 2005 - 2007, due to "current leakage" which caused increased chip heat and power consumption. Afterwards, chip manufacturers began adding additional cores, instead of optimizing for increased frequencies.</p>
<h3>Moore's Law</h3>
<p>From Wikipedia: <a href="https://en.wikipedia.org/wiki/Moore%27s_law">wiki/Moores_law</a></p>
<blockquote>
<p>Moore's law is the observation that the number of transistors in a dense integrated circuit doubles about every two years. The observation is named after Gordon Moore, the co-founder of Fairchild Semiconductor and CEO of Intel, whose 1965 paper described a doubling every year in the number of components per integrated circuit, and projected this rate of growth would continue for at least another decade. In 1975 looking forward to the next decade, he revised the forecast to doubling every two years, a compound annual growth rate (CAGR) of 41.4%.</p>
</blockquote>
<p>Unlike Dennard's Scaling, the definition of Moore's Law has less of a consenus. People are still debating exactly what the law covers. Cantrill defines Moore's Law a differently from the summary on Wikipedia. He uses references found in various interviews, articles and books to piece together what he thinks Moore's Law means.</p>
<p>From his <a href="https://www.slideshare.net/bcantrill/no-moore-left-to-give-enterprise-computing-after-moores-law">slides</a></p>
<blockquote>
<p>"...for many years, Moore's Law could be inferred to the doublings of density, speed and economics..."</p>
</blockquote>
<p>Moore's Law accounts for more than the doubling of density, which could theoritically be achieved at the cost of economics (moving to a more expensive material) or speed.</p>
<p>Cantrill argues that processors had become higher density, while also becoming cheaper for both manufacturers and consumers. This changed around 2015 when processors began becoming more expensive with each additional generation, even though transistor nodes had shrunk in size.</p>
<h3>Amdahl's Law</h3>
<p>From Wikipedia: <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">wiki/Amdahls_law</a></p>
<blockquote>
<p>In computer architecture, Amdahl's law (or Amdahl's argument[1]) is a formula which gives the theoretical speedup in latency of the execution of a task at fixed workload that can be expected of a system whose resources are improved. It is named after computer scientist Gene Amdahl, and was presented at the AFIPS Spring Joint Computer Conference in 1967.</p>
</blockquote>
<p>The most interesting of the "laws" is "Amdahl's Law" which refers to parallelism and the potiential speed improvements that can be gained by increasing core counts for a particular application.</p>
<p>Amdahl's refers to the speedup that can be expected from parallel computations as limited by the sequentional portion of the application. Applications can be divided into sequential and parallel portions, of which <em>P</em> defines the percentage of the application that executes in parallel.</p>
<p>The Wikipedia image shows the potential speedup with each additional core. The lines denote differing values for <em>P</em> (50%, 75%, 90% and 95%).
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/AmdahlsLaw.svg/1280px-AmdahlsLaw.svg.png" alt="https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/AmdahlsLaw.svg/1280px-AmdahlsLaw.svg.png"></p>
<p>The graph shows that an application with a 50% parallelized portion (such as Google Chrome) will not benefit from anymore than 16 processor cores. An application with 90% parallization will not benefit from more than 512 processor cores.</p>
<p>There's an informative video by <a href="https://www.youtube.com/watch?v=eJBOU23L720&#x26;t=442">Coreteks</a> titled <a href="https://www.youtube.com/watch?v=eJBOU23L720&#x26;t=442">Hardware trends: How many cores do we need?!</a> where he succinctly explains Amdahl's law and how it relates to CPUs, GPUs, ASICs and FPGAs. In the video he states that GPUs, ASICs and FPGAs are not necessarily solutions to CPU performance issues as they all suffer from Amdahl's law. Once a commonly performed tasks have a specialized ASIC created, there is not much that can be done beyond the hardware optimization work we've seen in the past. Transistor size reductions providing ~40% performance improvements every two years will no longer be the case. And tasks which cannot be fully parallelized will not benefit from being executed across many cores. Hence software developers will have to become more accustomed to optimizing their applications again.</p>
<h3>Microservices</h3>
<p>One consequence of Moore's Law ending is the proliferation of computing across many devices and computers. CPU computation will become distributed and closer to where it is needed. This is seen in the proliferation of IoT applications we have been seeing.</p>
<p>Part of this has been the push towards microservices. Microservice oriented architectures have the potential to suffer from the same constraints around scaling as Amdahl's law.</p>
<p>Though data is normally partitioned (ideally by more than the tenant), sometimes there's ends up being shared resources where data must be processed sequentially. These portions of the application can be rather difficult to scale.</p>
<p>What percentage of a user's request can be parallized in a distributed system? Are there transactions that need to occur? What about costly shared infrastructure such as queues or event streams?</p>
<p>If a request must go through a shared linear queue in a distributed system, this may limit how effective simply scaling the components around the queue will be.</p>
<p>When architecting distributed systems, careful consideration must be made about shared state if one wants to effectively understand how their system will scale. Simply increasing the number of web servers one has when their file storage is the bottleneck is not effective and can be counter productive.</p>
<h3>Future technologies</h3>
<p>There are many technologies in the pipeline of chip manufacturers including 2.5D and 3D packaging which allow for the addition of memory, ASICs, GPUs and other chiplets to be included on processor dies. By including these chiplets on processor dies, the amount of energy and time required to transfer data can be reduced. Making previously high latency tasks feasible in high performance computing.</p>
<p>Other technologies include asymethic processing cores, where CPU cores are designed for different tasks. One core may be designed for high performance single threaded applications such as web browsers, while other cores will be designed for parallizable vector computables used by graphics or video editing applications.</p>
<p>There are still improvements that can be made at the power and IPC level, but they will require changes in software and operating systems.</p>
<h3>Conclusion</h3>
<p>The take away from Cantrill's presentation is that computers aren't going to get <em>much</em> faster <strong><em>and</em></strong> cheaper from here. We will see some improvements in the amount of cores packed into a machine, but this may come at the cost of heat, price and memory latency.</p>
<p>The real outcome is going to be the proliferation of more computers being used in areas we previously did not expect and larger distributed systems being built across slower commodity hardware.</p></div></div></article></div></main></div><footer class="bg-accent-1 border-t border-accent-2"><div class="container mx-auto px-5"></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"QCon - No Moore Left to Give","date":"2019-08-14","slug":"2019-08-14-qcon-no-moore","content":"\u003cp\u003eBryan Cantrill is one of my favorite presenters, so I was excited to see that he'd be giving a keynote at QCon. For a long time, computer enthuasaists have been talking about the end of Moore's law and what it means for computing. What Cantrill explains is that Moore's law is close to ending, it's not the end of the world, but developers aren't going to get the \"free\" performance increases we've seen in the past.\u003c/p\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003ca href=\"https://www.infoq.com/presentations/moore-law-expiring/\"\u003eNo Moore Left to Give: Enterprise Computing after Moore's Law\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThis post is based on a \u003ca href=\"https://www.infoq.com/qconnewyork2019/\"\u003ekeynote presentation\u003c/a\u003e by Bryan Cantrill and is \u003ca href=\"https://www.infoq.com/presentations/moore-law-expiring/?itm_source=infoq\u0026#x26;itm_medium=popular_widget\u0026#x26;itm_campaign=popular_content_list\u0026#x26;itm_content=\"\u003efreely available on the InfoQ website.\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eBryan references three \"laws\" in his talk.\u003c/p\u003e\n\u003cp\u003eThe laws referenced are Dennard Scaling, Moore's Law and Amdahl's Law.\u003c/p\u003e\n\u003cp\u003eWhat Bryan argues is that Moore's Law is nearing its end and transistor sizes below 7nm are going to be more expensive and yield less benefits going forward. Programmers have become accustomed to computers becoming faster and cheaper every year, but this may no longer be the case.\u003c/p\u003e\n\u003cp\u003eI will quickly go over the three laws referenced by Cantrill in his talk.\u003c/p\u003e\n\u003ch3\u003eDennard Scaling\u003c/h3\u003e\n\u003cp\u003eFrom Wikipedia: \u003ca href=\"https://en.wikipedia.org/wiki/Dennard_scaling\"\u003ewiki/Dennard_scaling\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eDennard scaling, also known as MOSFET scaling, is a scaling law based on a 1974 paper co-authored by Robert H. Dennard, after whom it is named. Originally formulated for MOSFETs, it states, roughly, that as transistors get smaller, their power density stays constant, so that the power use stays in proportion with area; both voltage and current scale (downward) with length.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eDennard scaling meant that processors could go faster simply by increasing the frequency. From 100Mhz to 2GHz to 3GHz and so on. Frequency increases broke down somewhere in 2005 - 2007, due to \"current leakage\" which caused increased chip heat and power consumption. Afterwards, chip manufacturers began adding additional cores, instead of optimizing for increased frequencies.\u003c/p\u003e\n\u003ch3\u003eMoore's Law\u003c/h3\u003e\n\u003cp\u003eFrom Wikipedia: \u003ca href=\"https://en.wikipedia.org/wiki/Moore%27s_law\"\u003ewiki/Moores_law\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eMoore's law is the observation that the number of transistors in a dense integrated circuit doubles about every two years. The observation is named after Gordon Moore, the co-founder of Fairchild Semiconductor and CEO of Intel, whose 1965 paper described a doubling every year in the number of components per integrated circuit, and projected this rate of growth would continue for at least another decade. In 1975 looking forward to the next decade, he revised the forecast to doubling every two years, a compound annual growth rate (CAGR) of 41.4%.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eUnlike Dennard's Scaling, the definition of Moore's Law has less of a consenus. People are still debating exactly what the law covers. Cantrill defines Moore's Law a differently from the summary on Wikipedia. He uses references found in various interviews, articles and books to piece together what he thinks Moore's Law means.\u003c/p\u003e\n\u003cp\u003eFrom his \u003ca href=\"https://www.slideshare.net/bcantrill/no-moore-left-to-give-enterprise-computing-after-moores-law\"\u003eslides\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\"...for many years, Moore's Law could be inferred to the doublings of density, speed and economics...\"\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eMoore's Law accounts for more than the doubling of density, which could theoritically be achieved at the cost of economics (moving to a more expensive material) or speed.\u003c/p\u003e\n\u003cp\u003eCantrill argues that processors had become higher density, while also becoming cheaper for both manufacturers and consumers. This changed around 2015 when processors began becoming more expensive with each additional generation, even though transistor nodes had shrunk in size.\u003c/p\u003e\n\u003ch3\u003eAmdahl's Law\u003c/h3\u003e\n\u003cp\u003eFrom Wikipedia: \u003ca href=\"https://en.wikipedia.org/wiki/Amdahl%27s_law\"\u003ewiki/Amdahls_law\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eIn computer architecture, Amdahl's law (or Amdahl's argument[1]) is a formula which gives the theoretical speedup in latency of the execution of a task at fixed workload that can be expected of a system whose resources are improved. It is named after computer scientist Gene Amdahl, and was presented at the AFIPS Spring Joint Computer Conference in 1967.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eThe most interesting of the \"laws\" is \"Amdahl's Law\" which refers to parallelism and the potiential speed improvements that can be gained by increasing core counts for a particular application.\u003c/p\u003e\n\u003cp\u003eAmdahl's refers to the speedup that can be expected from parallel computations as limited by the sequentional portion of the application. Applications can be divided into sequential and parallel portions, of which \u003cem\u003eP\u003c/em\u003e defines the percentage of the application that executes in parallel.\u003c/p\u003e\n\u003cp\u003eThe Wikipedia image shows the potential speedup with each additional core. The lines denote differing values for \u003cem\u003eP\u003c/em\u003e (50%, 75%, 90% and 95%).\n\u003cimg src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/AmdahlsLaw.svg/1280px-AmdahlsLaw.svg.png\" alt=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/AmdahlsLaw.svg/1280px-AmdahlsLaw.svg.png\"\u003e\u003c/p\u003e\n\u003cp\u003eThe graph shows that an application with a 50% parallelized portion (such as Google Chrome) will not benefit from anymore than 16 processor cores. An application with 90% parallization will not benefit from more than 512 processor cores.\u003c/p\u003e\n\u003cp\u003eThere's an informative video by \u003ca href=\"https://www.youtube.com/watch?v=eJBOU23L720\u0026#x26;t=442\"\u003eCoreteks\u003c/a\u003e titled \u003ca href=\"https://www.youtube.com/watch?v=eJBOU23L720\u0026#x26;t=442\"\u003eHardware trends: How many cores do we need?!\u003c/a\u003e where he succinctly explains Amdahl's law and how it relates to CPUs, GPUs, ASICs and FPGAs. In the video he states that GPUs, ASICs and FPGAs are not necessarily solutions to CPU performance issues as they all suffer from Amdahl's law. Once a commonly performed tasks have a specialized ASIC created, there is not much that can be done beyond the hardware optimization work we've seen in the past. Transistor size reductions providing ~40% performance improvements every two years will no longer be the case. And tasks which cannot be fully parallelized will not benefit from being executed across many cores. Hence software developers will have to become more accustomed to optimizing their applications again.\u003c/p\u003e\n\u003ch3\u003eMicroservices\u003c/h3\u003e\n\u003cp\u003eOne consequence of Moore's Law ending is the proliferation of computing across many devices and computers. CPU computation will become distributed and closer to where it is needed. This is seen in the proliferation of IoT applications we have been seeing.\u003c/p\u003e\n\u003cp\u003ePart of this has been the push towards microservices. Microservice oriented architectures have the potential to suffer from the same constraints around scaling as Amdahl's law.\u003c/p\u003e\n\u003cp\u003eThough data is normally partitioned (ideally by more than the tenant), sometimes there's ends up being shared resources where data must be processed sequentially. These portions of the application can be rather difficult to scale.\u003c/p\u003e\n\u003cp\u003eWhat percentage of a user's request can be parallized in a distributed system? Are there transactions that need to occur? What about costly shared infrastructure such as queues or event streams?\u003c/p\u003e\n\u003cp\u003eIf a request must go through a shared linear queue in a distributed system, this may limit how effective simply scaling the components around the queue will be.\u003c/p\u003e\n\u003cp\u003eWhen architecting distributed systems, careful consideration must be made about shared state if one wants to effectively understand how their system will scale. Simply increasing the number of web servers one has when their file storage is the bottleneck is not effective and can be counter productive.\u003c/p\u003e\n\u003ch3\u003eFuture technologies\u003c/h3\u003e\n\u003cp\u003eThere are many technologies in the pipeline of chip manufacturers including 2.5D and 3D packaging which allow for the addition of memory, ASICs, GPUs and other chiplets to be included on processor dies. By including these chiplets on processor dies, the amount of energy and time required to transfer data can be reduced. Making previously high latency tasks feasible in high performance computing.\u003c/p\u003e\n\u003cp\u003eOther technologies include asymethic processing cores, where CPU cores are designed for different tasks. One core may be designed for high performance single threaded applications such as web browsers, while other cores will be designed for parallizable vector computables used by graphics or video editing applications.\u003c/p\u003e\n\u003cp\u003eThere are still improvements that can be made at the power and IPC level, but they will require changes in software and operating systems.\u003c/p\u003e\n\u003ch3\u003eConclusion\u003c/h3\u003e\n\u003cp\u003eThe take away from Cantrill's presentation is that computers aren't going to get \u003cem\u003emuch\u003c/em\u003e faster \u003cstrong\u003e\u003cem\u003eand\u003c/em\u003e\u003c/strong\u003e cheaper from here. We will see some improvements in the amount of cores packed into a machine, but this may come at the cost of heat, price and memory latency.\u003c/p\u003e\n\u003cp\u003eThe real outcome is going to be the proliferation of more computers being used in areas we previously did not expect and larger distributed systems being built across slower commodity hardware.\u003c/p\u003e"}},"__N_SSG":true},"page":"/posts/[slug]","query":{"slug":"2019-08-14-qcon-no-moore"},"buildId":"8hHALvY9GgZh87Tdh2K_K","assetPrefix":"/blog","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>